{
  "hash": "6a7670ea4b144046f0541163ac0013d8",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Julia for R users\n---\n\n\n\n> I know a lot of R and can do my daily job with it. Why should I learn Julia?\n\nIn my case, I was looking for some adventure. Haskell seemed too hard, Python too normal. So I went on a journey to learn Julia and was very happy with what I discovered.\n\nI love R, it is my breadwinner (and has been for the past 6 years), and because of that I know some of its limitations. So below is a (biased) list of features that may interest you in trying Julia:\n\n## You can run R inside of Julia\n\nNot sure where to begin in Julia? Start with R!\n\nWith `RCall` you can run R code inside Julia:\n\n\n::: {#0922260e .cell execution_count=2}\n``` {.julia .cell-code}\nusing RCall;\n\nR\"\"\"\nmedian(1:5)\n\"\"\"\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```\nRObject{IntSxp}\n[1] 3\n```\n:::\n:::\n\n\nYou can even pass objects from Julia to R and vice-versa:\n\n::: {#dbc7563a .cell execution_count=3}\n``` {.julia .cell-code}\nx = [1:5;]\n\n@rput x\n\nR\"median(x)\"\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\nRObject{IntSxp}\n[1] 3\n```\n:::\n:::\n\n\nThis R chunks in this Quarto notebook were made using RCall! See [RCall docs](https://juliainterop.github.io/RCall.jl/stable/gettingstarted/) for more details.\n\nYou can see some differences between R and Julia [here](https://docs.julialang.org/en/v1/manual/noteworthy-differences/#Noteworthy-differences-from-R).\n\n## There is a tidyverse in Julia and it is awesome\n\n[Tidier.jl](https://tidierorg.github.io/Tidier.jl/dev/) is a data analysis package inspired by R's tidyverse and crafted specifically for Julia. It is made with the macro magic described below. Behind the scenes, it is transformed in usual `Dataframes.jl` code.\n\n![Why not recreate an entire ecosystem using macros?](images/tidier.png)\n\nHere's an example from TidierData docs:\n\n::: {#655456bb .cell execution_count=4}\n``` {.julia .cell-code}\nusing TidierData\nusing RDatasets\n\nmovies = dataset(\"ggplot2\", \"movies\");\n\n@chain movies begin\n    @mutate(Budget = Budget / 1_000_000)\n    @filter(Budget >= mean(skipmissing(Budget)))\n    @select(Title, Budget)\n    @slice(1:5)\nend\n```\n:::\n\n\nIt looks like `dplyr` code with `@`s.\n\n## Fast Julia code is written in Julia; fast R code is not written in R\n\nIn R, whenever you need some *really* fast code (as fast as you would get in C), you have to use C or Fortran code. R is simply slow. If you need speed in R, you will have to find a package that already implements what you need or learn C/Fortran, use RCpp and pray.\n\n![`stringi` package sourcecode.](images/stringi-code.png)\n\nIn Julia, you won't need other language to get speed close to C. That's way they say that Julia [solves the two language problem](https://juliadatascience.io/julia_accomplish#sec:two_language). Julia packages are almost always 100% Julia, which means that you can look to its sourcecode and learn a lot.\n\n![Images that make you cry: the deep learning package [Flux.jl](https://github.com/FluxML/Flux.jl).](images/flux.png)\n\nThis is specially interesting if you read Julia Base sourcecode! How does Julia define the maximum of a vector? Type\n\n::: {#3b534a19 .cell execution_count=5}\n``` {.julia .cell-code}\n@edit maximum([1:5;])\n```\n:::\n\n\nand you will see this:\n\n![The sourcecode of the function maximum applied to a vector.](images/maximum-sourcecode.png)\n\nIt takes some time to grasp the meaning, but in the end it says \"apply a mapreduce into the vector, using the max function on each pair of numbers\". In R, the sourcecode is a sad `.Primitive(\"max\")`.\n\nIn Julia, to obtain maximum performance, you need to follow just two principles, as quoted from the excellent [Modern Julia Workflows](https://modernjuliaworkflows.org/optimizing/):\n\n- Ensure that the compiler can infer the type of every variable.\n- Avoid unnecessary (heap) allocations.\n\nFor me, it sounds easier than learn C++.\n\n## No need to vectorize code; loops, maps and broadcast are fast enough\n\nTired of writing loops? Julia has a special notation `.` (yes, a dot) to apply *any* function to a vector/array/iterable-object; this is called [*broadcasting*](https://docs.julialang.org/en/v1/manual/arrays/#Broadcasting). For example, you can apply the `power2` function in a vector as easy as\n\n::: {#0d1200a6 .cell execution_count=6}\n``` {.julia .cell-code}\n#julia\n# define power2 for numbers\npower2(x) = x^2;\n\n# apply in vectors\npower2.(1:10)\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\n10-element Vector{Int64}:\n   1\n   4\n   9\n  16\n  25\n  36\n  49\n  64\n  81\n 100\n```\n:::\n:::\n\n\nor in a matrix\n\n::: {#bbbe4ff8 .cell execution_count=7}\n``` {.julia .cell-code}\n#julia\nX = reshape([1:16;], (4, 4))\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\n4×4 Matrix{Int64}:\n 1  5   9  13\n 2  6  10  14\n 3  7  11  15\n 4  8  12  16\n```\n:::\n:::\n\n\n::: {#5be5cdfb .cell execution_count=8}\n``` {.julia .cell-code}\n#julia\npower2.(X)\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\n4×4 Matrix{Int64}:\n  1  25   81  169\n  4  36  100  196\n  9  49  121  225\n 16  64  144  256\n```\n:::\n:::\n\n\nWhen using infix functions like `+` or `=`, you put the dot before the operator, as in\n\n::: {#4e6085c8 .cell execution_count=9}\n``` {.julia .cell-code}\n#julia\n[1:5;] .+ 10\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\n5-element Vector{Int64}:\n 11\n 12\n 13\n 14\n 15\n```\n:::\n:::\n\n\nIn R, you always try to avoid loops because they are *slow*. Suppose you have a vector and want to sum 1 to every entry. As an experienced R programmer, you look for a vectorized approach:\n\n```r\n# R\nf1_vec = function(x) {\n    y = x + 1\n}\n```\n\ninstead of a loop\n\n```r\n# R\nf1_loop = function(x) {\n    y = x\n    for (i in seq_along(x)) y[i] = x[i] + 1\n    y\n}\n```\n\nor a even a `purrr::map` approach (if you are in a functional programming mood)\n\n```r\n#R\nf1_map = function(x) {\n    purrr::map_dbl(x, \\(xi) xi + 1)\n}\n```\n\nbecause the first options is faster. We can see the difference:\n\n```r\n# R\nx = 1:100000\n\nbench::mark(\n    f1_vec(x)\n    ,f1_loop(x)\n    ,f1_map(x)\n    ,relative = TRUE\n)\n```\n\n::: {#cdad1074 .cell execution_count=10}\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\nRObject{VecSxp}\n# A tibble: 3 × 13\n  expression   min median `itr/sec` mem_alloc `gc/sec` n_itr  n_gc total_time\n  <bch:expr> <dbl>  <dbl>     <dbl>     <dbl>    <dbl> <int> <dbl>   <bch:tm>\n1 f1_vec(x)    1      1       122.       1        11.0   833    11      501ms\n2 f1_loop(x)  42.9   13.4      11.0      1.03      1      75     1      500ms\n3 f1_map(x)  529.   146.        1        1.00     34.0     7    35      515ms\n# ℹ 4 more variables: result <list>, memory <list>, time <list>, gc <list>\n```\n:::\n:::\n\n\nIn my machine, the loop is ~12x slower and the map ~145x slower than the vectorized version.\n\nThe biggest problem for an R user is when the function you want to apply have no vectorized form. I usually have to make some kludges^[or [gambiarras](https://pt.wikipedia.org/wiki/Gambiarra), in Brasileirês] with dplyr verbs to do something that is much more logical when written with a loop/map.\n\nIn Julia, the three approachs are similar:\n\n::: {#6c4521e1 .cell execution_count=11}\n``` {.julia .cell-code}\n#julia\nf1_vec(x) = x .+ 1;\n\nfunction f1_loop(x)\n    y = similar(x)\n    @inbounds for i ∈ eachindex(x) y[i] = x[i] + 1 end\n    y\nend;\n\nfunction f1_map(x)\n    map(x) do xi\n        xi + 1 \n    end\nend;\n```\n:::\n\n\n::: {#a8ad4596 .cell execution_count=12}\n``` {.julia .cell-code}\n#julia\nusing BenchmarkTools;\nx = [1:100000;];\n\n@benchmark f1_vec($x)\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n\n::: {.ansi-escaped-output}\n```{=html}\n<pre>BenchmarkTools.Trial: 10000 samples with 1 evaluation per sample.\n Range <span class=\"ansi-bright-black-fg\">(</span><span class=\"ansi-cyan-fg ansi-bold\">min</span> … <span class=\"ansi-magenta-fg\">max</span><span class=\"ansi-bright-black-fg\">):  </span><span class=\"ansi-cyan-fg ansi-bold\">51.382 μs</span> … <span class=\"ansi-magenta-fg\"> 2.234 ms</span>  <span class=\"ansi-bright-black-fg\">┊</span> GC <span class=\"ansi-bright-black-fg\">(</span>min … max<span class=\"ansi-bright-black-fg\">): </span>0.00% … 92.81%\n Time  <span class=\"ansi-bright-black-fg\">(</span><span class=\"ansi-blue-fg ansi-bold\">median</span><span class=\"ansi-bright-black-fg\">):     </span><span class=\"ansi-blue-fg ansi-bold\">75.726 μs              </span><span class=\"ansi-bright-black-fg\">┊</span> GC <span class=\"ansi-bright-black-fg\">(</span>median<span class=\"ansi-bright-black-fg\">):    </span>0.00%\n Time  <span class=\"ansi-bright-black-fg\">(</span><span class=\"ansi-green-fg ansi-bold\">mean</span> ± <span class=\"ansi-green-fg\">σ</span><span class=\"ansi-bright-black-fg\">):   </span><span class=\"ansi-green-fg ansi-bold\">85.594 μs</span> ± <span class=\"ansi-green-fg\">48.602 μs</span>  <span class=\"ansi-bright-black-fg\">┊</span> GC <span class=\"ansi-bright-black-fg\">(</span>mean ± σ<span class=\"ansi-bright-black-fg\">):  </span>5.00% ±  9.14%\n    ▂▂ █<span class=\"ansi-blue-fg\">▂</span> <span class=\"ansi-green-fg\"> </span>                                                    \n  ▂▂██▄█<span class=\"ansi-blue-fg\">█</span>▃<span class=\"ansi-green-fg\">▄</span>▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂ ▃\n  51.4 μs<span class=\"ansi-bright-black-fg\">         Histogram: frequency by time</span>         299 μs <span class=\"ansi-bold\">&lt;</span>\n Memory estimate<span class=\"ansi-bright-black-fg\">: </span><span class=\"ansi-yellow-fg\">781.30 KiB</span>, allocs estimate<span class=\"ansi-bright-black-fg\">: </span><span class=\"ansi-yellow-fg\">2</span>.</pre>\n```\n:::\n\n:::\n:::\n\n\n::: {#7054efb6 .cell execution_count=13}\n``` {.julia .cell-code}\n#julia\n@benchmark f1_loop($x)\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n\n::: {.ansi-escaped-output}\n```{=html}\n<pre>BenchmarkTools.Trial: 10000 samples with 1 evaluation per sample.\n Range <span class=\"ansi-bright-black-fg\">(</span><span class=\"ansi-cyan-fg ansi-bold\">min</span> … <span class=\"ansi-magenta-fg\">max</span><span class=\"ansi-bright-black-fg\">):  </span><span class=\"ansi-cyan-fg ansi-bold\">56.761 μs</span> … <span class=\"ansi-magenta-fg\">487.885 μs</span>  <span class=\"ansi-bright-black-fg\">┊</span> GC <span class=\"ansi-bright-black-fg\">(</span>min … max<span class=\"ansi-bright-black-fg\">): </span>0.00% … 67.33%\n Time  <span class=\"ansi-bright-black-fg\">(</span><span class=\"ansi-blue-fg ansi-bold\">median</span><span class=\"ansi-bright-black-fg\">):     </span><span class=\"ansi-blue-fg ansi-bold\">74.960 μs               </span><span class=\"ansi-bright-black-fg\">┊</span> GC <span class=\"ansi-bright-black-fg\">(</span>median<span class=\"ansi-bright-black-fg\">):    </span>0.00%\n Time  <span class=\"ansi-bright-black-fg\">(</span><span class=\"ansi-green-fg ansi-bold\">mean</span> ± <span class=\"ansi-green-fg\">σ</span><span class=\"ansi-bright-black-fg\">):   </span><span class=\"ansi-green-fg ansi-bold\">85.545 μs</span> ± <span class=\"ansi-green-fg\"> 40.868 μs</span>  <span class=\"ansi-bright-black-fg\">┊</span> GC <span class=\"ansi-bright-black-fg\">(</span>mean ± σ<span class=\"ansi-bright-black-fg\">):  </span>4.82% ±  9.23%\n   █  <span class=\"ansi-blue-fg\">▂</span>  <span class=\"ansi-green-fg\"> </span>                                                      \n  ▃██▅<span class=\"ansi-blue-fg\">█</span>▅▄<span class=\"ansi-green-fg\">▃</span>▃▄▅▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▂▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂ ▃\n  56.8 μs<span class=\"ansi-bright-black-fg\">         Histogram: frequency by time</span>          316 μs <span class=\"ansi-bold\">&lt;</span>\n Memory estimate<span class=\"ansi-bright-black-fg\">: </span><span class=\"ansi-yellow-fg\">781.30 KiB</span>, allocs estimate<span class=\"ansi-bright-black-fg\">: </span><span class=\"ansi-yellow-fg\">2</span>.</pre>\n```\n:::\n\n:::\n:::\n\n\n::: {#37692477 .cell execution_count=14}\n``` {.julia .cell-code}\n#julia\n@benchmark f1_map($x)\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n\n::: {.ansi-escaped-output}\n```{=html}\n<pre>BenchmarkTools.Trial: 10000 samples with 1 evaluation per sample.\n Range <span class=\"ansi-bright-black-fg\">(</span><span class=\"ansi-cyan-fg ansi-bold\">min</span> … <span class=\"ansi-magenta-fg\">max</span><span class=\"ansi-bright-black-fg\">):  </span><span class=\"ansi-cyan-fg ansi-bold\">58.017 μs</span> … <span class=\"ansi-magenta-fg\">480.735 μs</span>  <span class=\"ansi-bright-black-fg\">┊</span> GC <span class=\"ansi-bright-black-fg\">(</span>min … max<span class=\"ansi-bright-black-fg\">): </span>0.00% … 74.99%\n Time  <span class=\"ansi-bright-black-fg\">(</span><span class=\"ansi-blue-fg ansi-bold\">median</span><span class=\"ansi-bright-black-fg\">):     </span><span class=\"ansi-blue-fg ansi-bold\">75.071 μs               </span><span class=\"ansi-bright-black-fg\">┊</span> GC <span class=\"ansi-bright-black-fg\">(</span>median<span class=\"ansi-bright-black-fg\">):    </span>0.00%\n Time  <span class=\"ansi-bright-black-fg\">(</span><span class=\"ansi-green-fg ansi-bold\">mean</span> ± <span class=\"ansi-green-fg\">σ</span><span class=\"ansi-bright-black-fg\">):   </span><span class=\"ansi-green-fg ansi-bold\">85.569 μs</span> ± <span class=\"ansi-green-fg\"> 40.296 μs</span>  <span class=\"ansi-bright-black-fg\">┊</span> GC <span class=\"ansi-bright-black-fg\">(</span>mean ± σ<span class=\"ansi-bright-black-fg\">):  </span>4.81% ±  9.18%\n   █  <span class=\"ansi-blue-fg\"> </span> <span class=\"ansi-green-fg\"> </span>                                                       \n  ▃█▆▃<span class=\"ansi-blue-fg\">▇</span>▄<span class=\"ansi-green-fg\">▃</span>▃▃▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▂▁▂▂▂▂▂▂▂▂▂▂▂▂ ▂\n  58 μs<span class=\"ansi-bright-black-fg\">           Histogram: frequency by time</span>          312 μs <span class=\"ansi-bold\">&lt;</span>\n Memory estimate<span class=\"ansi-bright-black-fg\">: </span><span class=\"ansi-yellow-fg\">781.30 KiB</span>, allocs estimate<span class=\"ansi-bright-black-fg\">: </span><span class=\"ansi-yellow-fg\">2</span>.</pre>\n```\n:::\n\n:::\n:::\n\n\nThis means that in Julia it is usual to *define a function using a scalar type* (a Number like Float64/Int or a String) *and then use broadcast* to apply the function to vectors/matrices/etc. No need to create vectorized forms of functions anymore!\n\n## The compiler is your friend\n\nSometimes you write code that won't make your parents proud. Suppose you create a function that sums all the numbers from 1 to a given `n`:\n\n::: {#f99f3d6a .cell execution_count=15}\n``` {.julia .cell-code}\nfunction f_sum(n)\n    s = 0\n    for i in 1:n\n        s += i\n    end\n\n    s\nend;\n```\n:::\n\n\nIn R, the language will obediently execute each iteration of the loop, as you demanded, and it will take forever. You are the boss.\n\nBut in Julia, we have this curious phenomena:\n\n::: {#ed3014e6 .cell execution_count=16}\n``` {.julia .cell-code}\n@time f_sum(100)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  0.000001 seconds\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=14}\n```\n5050\n```\n:::\n:::\n\n\n::: {#4882fc61 .cell execution_count=17}\n``` {.julia .cell-code}\n@time f_sum(100_000)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  0.000001 seconds\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=15}\n```\n5000050000\n```\n:::\n:::\n\n\n::: {#269f46f3 .cell execution_count=18}\n``` {.julia .cell-code}\n@time f_sum(100_000_000)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  0.000001 seconds\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=16}\n```\n5000000050000000\n```\n:::\n:::\n\n\nHow is it possible that it took the same time to run 100 iterations and 100 million iterations? The magic is the compiler: it understood that what you are doing is the sum of the terms of an [arithmetic progression](https://en.wikipedia.org/wiki/Arithmetic_progression). The legend says that Gauss deduced the formula for its sum, and the compiler did the same for you. No need to be as smart as Gauss while using Julia.\n\nJulia is a [just-in-time (JIT) compiled language](https://docs.julialang.org/en/v1/#man-julia-compared-other-languages), which means that each function is compiled when you first execute it. The \"time to first compile\" was a problem in the past, but from Julia 1.8 onwards it is not a big deal. The compiler is your friend, and almost always you can trust him.\n\n\n## Multiple dispatch and type system\n\nA type system is a way to organize data types within an hierarchy. Think of it as mathematical sets: you have the real numbers, and inside it are the rationals, the integers, the naturals, etc. Each one of these types store data into memory in a different manner (integers can be stored more efficiently than arbitrary real numbers, for example). Julia has a really nice [type system](https://docs.julialang.org/en/v1/manual/types/). Let's see some examples to better understand it.\n\nConsider the `print` function in R. It is a *generic* function, which means that its behaviour depends on the class/type of its first argument. This can be seen when we look to its misterious source code:\n\n![The `print` function sourcecode.](images/print-code.png)\n\nwhich means that `print` will use several `methods` (implementations/pieces-of-code), one for each class/type. Actually, R just creates a different function for each class, with the pattern `{function}.{class}`: \n\n![Each method/implementation of the generic function `print`.](images/print-methods.png)\n\nIn Julia, *every function is generic*. We can use the same function name and define different behaviours/implementations for each combination of classes/types of its arguments. We saw above the implementation of the `maximum` function in Julia for an arbitrary vector of numbers. But what if the vector is of a different kind, for which it is easier to determine its maximum?\n\nTake, for example, the object\n\n::: {#ecbae9ab .cell execution_count=19}\n``` {.julia .cell-code}\nx = 1:10\n```\n\n::: {.cell-output .cell-output-display execution_count=17}\n```\n1:10\n```\n:::\n:::\n\n\nIt is *not* a vector (to create a usual vector from 1 to 10, you type `[1:10;]`). Actually, its type is\n\n::: {#26121dbf .cell execution_count=20}\n``` {.julia .cell-code}\ntypeof(x)\n```\n\n::: {.cell-output .cell-output-display execution_count=18}\n```\nUnitRange{Int64}\n```\n:::\n:::\n\n\nand its type hierarchy is\n\n::: {#1c551c3c .cell execution_count=21}\n``` {.julia .cell-code}\nBase.show_supertypes(typeof(x))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nUnitRange{Int64} <: AbstractUnitRange{Int64} <: OrdinalRange{Int64, Int64} <: AbstractRange{Int64} <: AbstractVector{Int64} <: Any\n```\n:::\n:::\n\n\nSo `x` is a much simpler object than a vector: it is an increasing sequence of integer numbers, each 1 unity bigger than the previous one. It makes sense then that the `maximum` function can be defined much more simpler for an object of type `UnitRange{Int64}`: the biggest element is always the last.\n\nIf you look at the sourcecode\n\n::: {#3ecef1e7 .cell execution_count=22}\n``` {.julia .cell-code}\n@edit maximum(1:10)\n```\n:::\n\n\nyou will get\n\n::: {#3ccdff44 .cell execution_count=23}\n``` {.julia .cell-code}\nmaximum(r::AbstractUnitRange) = isempty(r) ? throw(ArgumentError(\"range must be non-empty\")) : last(r)\n```\n:::\n\n\nwhich is exactly what we thought: \n\n> is the range non-empty? Then take de last element; otherwise, an error.\n\nThe function `last` is defined for every children of type `AbstractUnitRange`, and so `maximum` is well defined.\n\nIn summary: Julia has an arbitrary `maximum` function for arbitrary vectors, but has specialized methods for some other specific types. This is a common pattern in Julia, and much of its performance depends on this. \n\n\n## Macros rewrite code without typing\n\n[Macros](https://docs.julialang.org/en/v1/manual/metaprogramming/) are one of the most powerful tools in Julia. They rewrite your code before executing it: it is a metaprogramming technique. When creating macros, you will have to understand how a bunch of characters are interpreted by the language and executed as code. This means that macros can rewrite pieces of code and add functionalities that are not possible simply with functions.\n\nWe already used some macros on this notebook; they all start with the `@` symbol. \n\nHow much time does it take to calculate the sin of a million numbers?\n\n::: {#6625b816 .cell execution_count=24}\n``` {.julia .cell-code}\n@time sin.(1:1_000_000);\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  0.018168 seconds (2 allocations: 7.629 MiB)\n```\n:::\n:::\n\n\nDo you have a loop and want to see a progress bar? No need to change the code inside the loop:\n\n::: {#6aa87a47 .cell execution_count=25}\n``` {.julia .cell-code}\nusing ProgressMeter;\n\n@showprogress for i in 1:10\n    sleep(0.1)\nend\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\rProgress:  20%|████████▎                                |  ETA: 0:00:07\rProgress:  90%|████████████████████████████████████▉    |  ETA: 0:00:00\rProgress: 100%|█████████████████████████████████████████| Time: 0:00:03\n```\n:::\n:::\n\n\nAs we've seen, even the tidyverse could be recreated in Julia using macros!\n\n\n## Multithreading is trivial\n\n[Multithreading](https://docs.julialang.org/en/v1/manual/multi-threading/) (or parallel computing) is when your code uses more than one processor at the same time. Multithreading in R is a bit complicated and actually create copies of the R process that comunicates with the main process. There is a [`futureverse`](https://www.futureverse.org/packages-overview.html) to deal with that in R, and plans like `callr` or `multisession` to define how these extra R sessions will be created and mantained.\n\nIn Julia, multithreading is as easy as appending a macro before a loop:\n\n::: {#ae039c62 .cell execution_count=26}\n``` {.julia .cell-code}\nThreads.@threads for i = 1:10\n    a[i] = Threads.threadid()\nend\n```\n:::\n\n\nIf you want a multithread version of `map` and `reduce` and so on, check [ThreadsX.jl](https://github.com/tkf/ThreadsX.jl).\n\nMultithread is recommended when you:\n- have some spare RAM;\n- have more than 1 processor;\n- want to apply some function on a list of things that take some time idling (for example, waiting for an API return something) or are not RAM-heavy (calculating small distance matrices).\n\nMy tipical use case is when I have a large dataframe and want to apply a function to several parts of it, based on a grouping variable. I split the dataframe into a vector of dataframes (with `groupby` and `collect`) and then apply the function in parallel.\n\nAnother use is the following: suppose you want to create an API to serve 5 simultaneous users requesting data all day. In R you will use [`plumber`](https://www.rplumber.io/) and make lots of `future_promise` calls. In Julia, just use [`Oxygen.jl`](https://oxygenframework.github.io/Oxygen.jl/stable/#Multithreading-and-Parallelism) without any need to change your code: the requests are made in parallel.\n\n## Packages are a joy to use\n\nIn R, you have 2 options to call a function from another package:\n\n- use `library(PACKAGE)`, which imports *every* function from PACKAGE to your namespace;\n- use `PACKAGE::FUNCTION` every time you want to use a function.\n\nPackages like [`box`](https://klmr.me/box/) are a more \"Pythonesque\" approach to importing libraries, and allow to import just some parts of a package.\n\nIn Julia, a package is just a module, and you have:\n\n- `using PACKAGE` is analogous to R `library(PACKAGE)`;\n- `import PACKAGE` and then `PACKAGE.FUNCTION` in every call;\n- `using PACKAGE: FUNCTION1, FUNCTION2` will import only these 2 functions from PACKAGE.\n\nThe best part, however, is the ability to create modules inside modules. For example, if you have a mega package to do all your data analysis in your work, you can have a module about Reports, another one with APIs and so on. Importing then can be done with\n\n::: {#43a01eda .cell execution_count=27}\n``` {.julia .cell-code}\nusing MyPackage.Reports\n\n# or\nimport MyPackage.APIs as API\n\nMD.api1()\n```\n:::\n\n\nThis approach resembles a little the idea of namespaces in [shiny modules](https://mastering-shiny.org/scaling-modules.html), and using `box` is how the [`rhino`](https://appsilon.github.io/rhino/articles/explanation/box-modules.html) emulate the \"module inside module\" thing.\n\n## Math symbols for the math enthusiasts\n\nExamples of correct Julia code:\n\n::: {#2e9eec29 .cell execution_count=28}\n``` {.julia .cell-code}\n[1, 2] ∩ [2, 3]\n```\n\n::: {.cell-output .cell-output-display execution_count=22}\n```\n1-element Vector{Int64}:\n 2\n```\n:::\n:::\n\n\n::: {#3ae225ad .cell execution_count=29}\n``` {.julia .cell-code}\n2 ∈ [2, 3]\n```\n\n::: {.cell-output .cell-output-display execution_count=23}\n```\ntrue\n```\n:::\n:::\n\n\n::: {#a4d6ead2 .cell execution_count=30}\n``` {.julia .cell-code}\nf(r) = π*r^2\n\nf(3)\n```\n\n::: {.cell-output .cell-output-display execution_count=24}\n```\n28.274333882308138\n```\n:::\n:::\n\n\n::: {#08f0b6ae .cell execution_count=31}\n``` {.julia .cell-code}\n# Euler's identity\nℯ^(im * π) + 1 |> round\n```\n\n::: {.cell-output .cell-output-display execution_count=25}\n```\n0.0 + 0.0im\n```\n:::\n:::\n\n\n---\n\nIf I convinced you or sparked just a little interest, you can start your own journey in Julialand with the suggested steps:\n\n1. [Modern Julia Workflows](https://modernjuliaworkflows.org): install Julia, setup your IDE and learn the basics of how to run code.\n2. [The julia docs] are excellent: need to understand more about [variables](https://docs.julialang.org/en/v1/manual/variables/)? What about the [scope of functions](https://docs.julialang.org/en/v1/manual/functions/)? [Types](https://docs.julialang.org/en/v1/manual/types/) is certainly worth a read!\n3. [Think Julia](https://benlauwens.github.io/ThinkJulia.jl/latest/book.html), by Be Lauwens and Allen Doeney: similar to Think Python, but better!\n4. Questions? Go to the [Julia Discourse](https://discourse.julialang.org/).\n5. For a list of really nice packages, see [this repo](https://gensjulia.pages.dev/data-science/#general-purpose).\n\n",
    "supporting": [
      "julia-for-r-users_files"
    ],
    "filters": [],
    "includes": {}
  }
}