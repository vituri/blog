{
  "hash": "1cc3fcd25c7366167e17578318e0bb93",
  "result": {
    "engine": "jupyter",
    "markdown": "---\n# engine: julia\njupyter: julia-1.10\n---\n\n# Julia for R users\n\n> I know a lot of R and can do my daily job with it. Why should I learn Julia?\n\nIn my case, I was looking for some adventure. Haskell seemed too hard, Python too normal. So I went on a journey to learn Julia and was very happy with what I discovered.\n\nBelow is a (biased) list of advantages of Julia compared to R:\n\n## Fast Julia code is written in Julia; fast R code is not written in R\n\nIn R, whenever you need some *really* fast code (as fast as you would get in C), you have to use C or Fortran code. R is simply slow. If you need speed in R, you will have to find a package that already implements what you need or learn C/Fortran, use RCpp and pray.\n\n![`stringi` package sourcecode.](images/stringi-code.png)\n\nIn Julia, you won't need other language to get speed close to C. That's way they say that Julia [solves the two language problem](https://juliadatascience.io/julia_accomplish#sec:two_language). Julia packages are almost always 100% Julia, which means that you can look to its sourcecode and learn a lot.\n\n![Images that make you cry: the deep learning package [Flux.jl](https://github.com/FluxML/Flux.jl).](images/flux.png)\n\nThis is specially interesting if you read Julia Base sourcecode! How does Julia define the maximum of a vector? Type\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\n@edit maximum([1:5;])\n```\n:::\n\n\nand you will see this:\n\n![The sourcecode of the function maximum applied to a vector.](images/maximum-sourcecode.png)\n\nIt takes some time to grasp the meaning, but in the end it says \"apply a mapreduce into the vector, using the max function on each pair of numbers\". In R, the sourcecode is a sad `.Primitive(\"max\")`.\n\n## No need to vectorize code; loops, maps and broadcast are fast enough\n\nJulia has a special notation `.` (yes, a dot) to apply *any* function to a vector/array/iterable-object; this is called [*broadcasting*](https://docs.julialang.org/en/v1/manual/arrays/#Broadcasting). For example, you can apply the `power2` function in a vector as easy as\n\n::: {.cell execution_count=2}\n``` {.julia .cell-code}\n#julia\n# define power2 for numbers\npower2(x) = x^2;\n\n# apply in vectors\npower2.(1:10)\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```\n10-element Vector{Int64}:\n   1\n   4\n   9\n  16\n  25\n  36\n  49\n  64\n  81\n 100\n```\n:::\n:::\n\n\nor in a matrix\n\n::: {.cell execution_count=3}\n``` {.julia .cell-code}\n#julia\nX = reshape([1:16;], (4, 4))\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```\n4×4 Matrix{Int64}:\n 1  5   9  13\n 2  6  10  14\n 3  7  11  15\n 4  8  12  16\n```\n:::\n:::\n\n\n::: {.cell execution_count=4}\n``` {.julia .cell-code}\n#julia\npower2.(X)\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\n4×4 Matrix{Int64}:\n  1  25   81  169\n  4  36  100  196\n  9  49  121  225\n 16  64  144  256\n```\n:::\n:::\n\n\nWhen using infix functions like `+` or `=`, you put the dot before the operator, as in\n\n::: {.cell execution_count=5}\n``` {.julia .cell-code}\n#julia\n[1:5;] .+ 10\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```\n5-element Vector{Int64}:\n 11\n 12\n 13\n 14\n 15\n```\n:::\n:::\n\n\nIn R, you always try to avoid loops because they are *slow*. Suppose you have a vector and want to sum 1 to every entry. As an experienced R programmer, you look for a vectorized approach:\n\n\n```{r}\n#| eval: false\n# R\nf1_vec = function(x) {\n    y = x + 1\n}\n```\n\ninstead of a loop\n\n```{r}\n#| eval: false\n# R\nf1_loop = function(x) {\n    y = x\n    for (i in seq_along(x)) y[i] = x[i] + 1\n    y\n}\n```\n\nor a even a `purrr::map` approach\n\n```{r}\n#| eval: false\n#R\nf1_map = function(x) {\n    purrr::map_dbl(x, \\(xi) xi + 1)\n}\n```\n\n\nbecause the first options is faster. We can see the difference:\n\n```{r}\n#| eval: false\n# R\nx = 1:100000\n\nbench::mark(\n    f1_vec(x)\n    ,f1_loop(x)\n    ,f1_map(x)\n    ,relative = TRUE\n)\n```\n\n::: {.cell execution_count=7}\n``` {.julia .cell-code}\n#R\nR\"\"\"\nf1_vec = function(x) {\n    y = x + 1\n}\n\nf1_loop = function(x) {\n    y = x\n    for (i in seq_along(x)) y[i] = x[i] + 1\n    y\n}\n\nf1_map = function(x) {\n    purrr::map_dbl(x, \\(xi) xi + 1)\n}\n\nx = 1:100000\n\nbench::mark(\n    f1_vec(x)\n    ,f1_loop(x)\n    ,f1_map(x)\n    ,relative = TRUE\n)\n\"\"\"\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n┌ Warning: RCall.jl: Aviso: Some expressions had a GC in every iteration; so filtering is disabled.\n└ @ RCall ~/.julia/packages/RCall/0ggIQ/src/io.jl:172\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=16}\n```\nRObject{VecSxp}\n# A tibble: 3 × 13\n  expression   min median `itr/sec` mem_alloc `gc/sec` n_itr  n_gc total_time\n  <bch:expr> <dbl>  <dbl>     <dbl>     <dbl>    <dbl> <int> <dbl>   <bch:tm>\n1 f1_vec(x)    1      1      122.        1.50    13.2    833    13      500ms\n2 f1_loop(x)  48.1   14.4      9.99      1.50     1       69     1      506ms\n3 f1_map(x)  524.   145.       1         1        8.88     7     9      513ms\n# ℹ 4 more variables: result <list>, memory <list>, time <list>, gc <list>\n```\n:::\n:::\n\n\nIn my machine, the loop is ~40x slower and the map ~500x slower than the vectorized version.\n\nIn Julia, the three approachs are similar:\n\n::: {.cell execution_count=8}\n``` {.julia .cell-code}\n#julia\nf1_vec(x) = x .+ 1;\n\nfunction f1_loop(x)\n    y = similar(x)\n    @inbounds for i ∈ eachindex(x) y[i] = x[i] + 1 end\n    y\nend;\n\nfunction f1_map(x)\n    map(x) do xi\n        xi + 1 \n    end\nend;\n```\n:::\n\n\n::: {.cell execution_count=9}\n``` {.julia .cell-code}\n#julia\nusing BenchmarkTools;\nx = [1:100000;];\n\n@benchmark f1_vec($x)\n```\n:::\n\n\n::: {.cell execution_count=10}\n``` {.julia .cell-code}\n#julia\n@benchmark f1_loop($x)\n```\n:::\n\n\n::: {.cell execution_count=11}\n``` {.julia .cell-code}\n#julia\n@benchmark f1_map($x)\n```\n:::\n\n\nThis means that in Julia it is usual to *define a function using a scalar type* (a Number like Float64/Int or a String) *and then use broadcast* to apply the function to vectors/matrices/etc.\n\n## The compiler is your friend\n\n## Multiple dispatch and a rich type system\n\nA type system is a way to create a hierarchy of data ..........?\n\nConsider de `print` function in R. It is a *generic* function, which means that its behaviour depends on the class of its first argument. This can be seen when we look to its misterious source code:\n\n![The `print` function sourcecode.](images/print-code.png)\n\nwhich means that `print` will use several `methods`, one for each class. Actually, R just creates a different function for each class, with the pattern `function.class`: \n\n![Each method/implementation of the generic function `print`.](images/print-methods.png)\n\nIn Julia, *every function is generic*. This means that we can use the same function name and define different behaviours/implementations for each combination of classes/types of its arguments.\n\n## Macros rewrite code without typing\n\n## Multithreading is trivial\n\n## Modules and packages are a joy to use\n\nIn R, you have 2 options to call a function from another package:\n\n- use `library(PACKAGE)` and then import *every* function from PACKAGE to your namespace;\n- use `PACKAGE::FUNCTION` every time you want to use a function.\n\nIn Julia, you have more options:\n\n- a\n- b\n- c\n\nThere is also the possibility to create modules inside modules (which are like packages inside packages). For example, if you have a package to train machine learning modules, you can have a module about Metrics, another one with Models and so on. Importing then can be done with\n\n::: {.cell execution_count=12}\n``` {.julia .cell-code}\nusing MyPackage.Metrics\n\n# or\nimport MyPackage.Models as MD\n```\n:::\n\n\n",
    "supporting": [
      "post_files/figure-pdf"
    ],
    "filters": []
  }
}